ğŸš§ Project Highlight â€” Claim Approval Prediction using Synthetic Data

I explored a multiclass classification problem to predict healthcare claim statuses (Approved, Denied, Pending) using a synthetic dataset generated by Faker (via Kaggle).

âœ… Steps I followed:
- Cleaned and encoded mixed data types
- Built pipelines using RandomForest, SVC, and XGBoost with SelectFromModel
- Used train-test split and cross-validation

â— Key Finding:
 Despite trying multiple models and tuning, the highest accuracy hovered around ~36%.

ğŸ“‰ Why so low?
1) The dataset was fully synthetic, generated without real-world relationships between features and targets.
2) This project reminded me that good models require good data. Without real patterns, even the best ML pipelines canâ€™t do much.

ğŸ’¡ Realizing this, I shifted to unsupervised learning, thinking that uncorrelated data may still hold natural clusters. I applied PCA to reduce dimensionality and used Clustering to group the data into 3 clusters 'hoping to uncover hidden structure'.
ğŸ“‰ However, the cluster compositions were nearly identical in terms of claim status distribution. Each cluster had an almost equal mix of Approved, Denied, and Pending claims â€” suggesting no significant separation exists even in unsupervised space.

ğŸ” Key Takeaway:
 This project reinforced an important lesson â€” not all datasets contain patterns worth modeling, and understanding when a model doesnâ€™t work is just as valuable as when it does.
